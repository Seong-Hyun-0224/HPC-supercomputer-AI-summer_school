{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E9nc7uOPZD21"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# variables\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "verbose = 1\n",
        "output_class = 10\n",
        "validation_split = 0.2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist 데이터를 로드한다\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# 입력을 0~1 사이로 전처리 수행\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# 레이블을 원핫 인코딩\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, output_class)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, output_class)\n"
      ],
      "metadata": {
        "id": "8F8LDQ3nZSMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4cee24-7fff-4a51-8a3b-877ff443dd4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy-2m9qoxHbS",
        "outputId": "701cba46-f18a-4838-be63-1e3473be6b47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hwsVBJsQKDb",
        "outputId": "c0a68ac2-2600-48ce-d906-a4b7f04490e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqgzc-_0naWX",
        "outputId": "d6eb7904-d559-4f1c-9767-59c2413a4fba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QliipMjwTZE",
        "outputId": "8e9acacf-c9cf-4dee-bacd-184319a0a8ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiOaHA8SwUhP",
        "outputId": "cbafac99-145c-4974-976e-a041ca7bc194"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
              "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
              "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
              "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
              "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
              "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
              "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
              "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
              "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
              "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
              "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
              "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "image = np.reshape(X_train[1], [28,28])\n",
        "plt.imshow(image, cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "nkJVClzOwwwF",
        "outputId": "2af5cd39-1ec9-4a3f-9632-b70d15221838"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9chVJEDwaNJ",
        "outputId": "2a735cc2-0c03-49d3-b162-a76c7de4e5e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# models\n",
        "model = tf.keras.models.Sequential()\n",
        "model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                           keras.layers.Dense(128, activation='relu'),\n",
        "                           keras.layers.Dense(10, activation='softmax') ])\n",
        "# model 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZu5nUxnUgR",
        "outputId": "38ff44d8-6926-4277-b493-3edad533ee6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DjhRA9z6mYFs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model 학습\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_split=validation_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukrpDf8GmhOO",
        "outputId": "dcac54bf-0032-4988-c977-bdd03cddb7e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 7s 16ms/step - loss: 0.4030 - accuracy: 0.8900 - val_loss: 0.2133 - val_accuracy: 0.9417\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.1898 - accuracy: 0.9464 - val_loss: 0.1612 - val_accuracy: 0.9556\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1366 - accuracy: 0.9609 - val_loss: 0.1299 - val_accuracy: 0.9638\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1072 - accuracy: 0.9695 - val_loss: 0.1177 - val_accuracy: 0.9653\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0865 - accuracy: 0.9752 - val_loss: 0.1030 - val_accuracy: 0.9701\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0711 - accuracy: 0.9799 - val_loss: 0.0952 - val_accuracy: 0.9724\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0601 - accuracy: 0.9833 - val_loss: 0.0926 - val_accuracy: 0.9727\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0496 - accuracy: 0.9862 - val_loss: 0.0880 - val_accuracy: 0.9732\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9881 - val_loss: 0.0888 - val_accuracy: 0.9727\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.0957 - val_accuracy: 0.9708\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.0880 - val_accuracy: 0.9759\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 0.0851 - val_accuracy: 0.9762\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.0833 - val_accuracy: 0.9758\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.0965 - val_accuracy: 0.9737\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0863 - val_accuracy: 0.9761\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.0876 - val_accuracy: 0.9765\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0880 - val_accuracy: 0.9763\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0902 - val_accuracy: 0.9760\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0942 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0934 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0944 - val_accuracy: 0.9783\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0979 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.1045 - val_accuracy: 0.9756\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1032 - val_accuracy: 0.9768\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.1083 - val_accuracy: 0.9760\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1036 - val_accuracy: 0.9769\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 9.4051e-04 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 7.5514e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9791\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 6.4413e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9782\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 5.9538e-04 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9785\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 8.5227e-04 - accuracy: 0.9999 - val_loss: 0.1218 - val_accuracy: 0.9760\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.1257 - val_accuracy: 0.9743\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.1117 - val_accuracy: 0.9769\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 8.1267e-04 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9783\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 4.8981e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9783\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 4.0507e-04 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9787\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 3.6096e-04 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9780\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 3.2137e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9787\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 3.0121e-04 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9779\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.7369e-04 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9783\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.3778e-04 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9784\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 8.0289e-04 - accuracy: 0.9998 - val_loss: 0.1639 - val_accuracy: 0.9707\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1269 - val_accuracy: 0.9750\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1193 - val_accuracy: 0.9787\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 4.2661e-04 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9787\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.7934e-04 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf771d29e0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy: ', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff_lgiG2m6Ot",
        "outputId": "633f0bbb-af0a-41f3-ac43-a10f28762bc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9795\n",
            "Test accuracy:  0.9794999957084656\n"
          ]
        }
      ]
    }
  ]
}